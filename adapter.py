# -*- coding: utf-8 -*-
"""Adapter2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XjSYmty4dTwdI1JUJ-WysIYqx9d9Tvn5

# Install necessary libraries
"""

!pip install transformers datasets

"""# Import necessary libraries"""

from datasets import load_dataset, concatenate_datasets, Dataset, load_metric
from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments
import numpy as np
from sklearn.model_selection import train_test_split
import torch
from sklearn.metrics import precision_score, recall_score, f1_score

"""# Check if GPU is available"""

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

"""# Load the IMDB Movie Review dataset"""

dataset = load_dataset("imdb")

"""# Load the RoBERTa tokenizer and model"""

model = RobertaForSequenceClassification.from_pretrained("distilroberta-base", num_labels=2)
tokenizer = RobertaTokenizer.from_pretrained("distilroberta-base")
model.to(device)  # Move the model to the GPU

"""# Preprocess the data"""

def preprocess_function(examples):
    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)

encoded_dataset = dataset.map(preprocess_function, batched=True)

""" # Split the data into train and test sets"""

train_dataset = encoded_dataset['train']

# Separate the classes
class_0 = train_dataset.filter(lambda x: x['label'] == 0)
class_1 = train_dataset.filter(lambda x: x['label'] == 1)

# Split the classes separately to maintain balance
train_0, test_0 = train_test_split(class_0, test_size=0.2, random_state=42)
train_1, test_1 = train_test_split(class_1, test_size=0.2, random_state=42)

# Convert lists back to Dataset objects
train_0 = Dataset.from_dict(train_0)
train_1 = Dataset.from_dict(train_1)
test_0 = Dataset.from_dict(test_0)
test_1 = Dataset.from_dict(test_1)

# Combine the split datasets using concatenate_datasets
train_dataset = concatenate_datasets([train_0, train_1])
test_dataset = concatenate_datasets([test_0, test_1])

"""# After processing the dataset, clear unnecessary variables"""

del dataset, encoded_dataset
import gc
gc.collect()  # Force garbage collection

"""# Define the metric for evaluation"""

accuracy_metric = load_metric("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)["accuracy"]
    precision = precision_score(labels, predictions, average="binary", zero_division=1)
    recall = recall_score(labels, predictions, average="binary", zero_division=1)
    f1 = f1_score(labels, predictions, average="binary", zero_division=1)
    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}

"""# Define the training arguments"""

training_args = TrainingArguments(
    output_dir="./results",               # Directory where model predictions and checkpoints will be written
    eval_strategy="epoch",                # Evaluation strategy: perform evaluation at the end of each epoch
    save_strategy="epoch",                # Save strategy: save the model checkpoint at the end of each epoch
    learning_rate=5e-5,                   # Learning rate for the optimizer
    per_device_train_batch_size=8,        # Batch size per GPU/TPU for training
    per_device_eval_batch_size=8,         # Batch size per GPU/TPU for evaluation
    num_train_epochs=3,                   # Number of training epochs
    weight_decay=0.01,                    # Weight decay to apply (if any) for regularization
    save_total_limit=2,                  # Limit the total number of checkpoints to save. Older checkpoints will be deleted
    load_best_model_at_end=True,          # Whether to load the best model (based on the metric specified) at the end of training
    metric_for_best_model="f1",           # Metric to use for selecting the best model. The model with the highest F1 score will be saved
)

"""# Initialize the Trainer"""

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
)

"""# Train the model"""

trainer.train()

"""# Evaluate the model"""

metrics = trainer.evaluate()
print(metrics)

"""# Save the model and tokenizer"""

model.save_pretrained("./imdb_finetuned_roberta")
tokenizer.save_pretrained("./imdb_finetuned_roberta")

from collections import Counter

# Checking class distribution in the evaluation set
print(Counter(test_dataset['label']))